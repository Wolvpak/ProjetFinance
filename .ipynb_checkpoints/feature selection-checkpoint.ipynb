{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e4be916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped Index(['trend_psar_up', 'trend_psar_down', 'alpha26', 'alpha45'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from all_indicators import get_all_stock_indicators\n",
    "data = get_all_stock_indicators('TKO.PA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38f35e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsfresh import extract_features\n",
    "import pandas as pd\n",
    "data['id']=pd.to_datetime(data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af53c354",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9f00760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Returns</th>\n",
       "      <th>Log Returns</th>\n",
       "      <th>ema5</th>\n",
       "      <th>ema8</th>\n",
       "      <th>ema12</th>\n",
       "      <th>ema16</th>\n",
       "      <th>ema20</th>\n",
       "      <th>ema26</th>\n",
       "      <th>sma5</th>\n",
       "      <th>sma8</th>\n",
       "      <th>sma12</th>\n",
       "      <th>sma16</th>\n",
       "      <th>sma20</th>\n",
       "      <th>sma26</th>\n",
       "      <th>macd_24_52</th>\n",
       "      <th>macd_12_26</th>\n",
       "      <th>adx7</th>\n",
       "      <th>adx10</th>\n",
       "      <th>adx20</th>\n",
       "      <th>adx30</th>\n",
       "      <th>rsi7</th>\n",
       "      <th>rsi10</th>\n",
       "      <th>rsi14</th>\n",
       "      <th>rsi17</th>\n",
       "      <th>rsi20</th>\n",
       "      <th>rsi25</th>\n",
       "      <th>stochrsi7</th>\n",
       "      <th>stochrsi10</th>\n",
       "      <th>stochrsi14</th>\n",
       "      <th>stochrsi17</th>\n",
       "      <th>stochrsi20</th>\n",
       "      <th>stochrsi25</th>\n",
       "      <th>willr10</th>\n",
       "      <th>willr14</th>\n",
       "      <th>willr17</th>\n",
       "      <th>...</th>\n",
       "      <th>alpha68</th>\n",
       "      <th>alpha74</th>\n",
       "      <th>alpha75</th>\n",
       "      <th>alpha78</th>\n",
       "      <th>alpha81</th>\n",
       "      <th>alpha83</th>\n",
       "      <th>alpha84</th>\n",
       "      <th>alpha85</th>\n",
       "      <th>alpha86</th>\n",
       "      <th>alpha94</th>\n",
       "      <th>alpha95</th>\n",
       "      <th>alpha99</th>\n",
       "      <th>alpha101</th>\n",
       "      <th>Sharpe 252</th>\n",
       "      <th>Sortino 252</th>\n",
       "      <th>Treynor 252</th>\n",
       "      <th>Beta 252</th>\n",
       "      <th>Sharpe 126</th>\n",
       "      <th>Sortino 126</th>\n",
       "      <th>Treynor 126</th>\n",
       "      <th>Beta 126</th>\n",
       "      <th>Sharpe 52</th>\n",
       "      <th>Sortino 52</th>\n",
       "      <th>Treynor 52</th>\n",
       "      <th>Beta 52</th>\n",
       "      <th>Sharpe 26</th>\n",
       "      <th>Sortino 26</th>\n",
       "      <th>Treynor 26</th>\n",
       "      <th>Beta 26</th>\n",
       "      <th>Var 252</th>\n",
       "      <th>CVar 252</th>\n",
       "      <th>Var 126</th>\n",
       "      <th>CVar 126</th>\n",
       "      <th>Var 52</th>\n",
       "      <th>CVar 52</th>\n",
       "      <th>Gold Close</th>\n",
       "      <th>WTI Oil Close</th>\n",
       "      <th>5Y TY ^FVX</th>\n",
       "      <th>CAC 40</th>\n",
       "      <th>CAC Returns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-12-05</th>\n",
       "      <td>0.018288</td>\n",
       "      <td>0.017305</td>\n",
       "      <td>0.020732</td>\n",
       "      <td>0.019288</td>\n",
       "      <td>0.059640</td>\n",
       "      <td>0.302623</td>\n",
       "      <td>0.317884</td>\n",
       "      <td>0.014615</td>\n",
       "      <td>0.012503</td>\n",
       "      <td>0.011552</td>\n",
       "      <td>0.011593</td>\n",
       "      <td>0.011744</td>\n",
       "      <td>0.012246</td>\n",
       "      <td>0.013532</td>\n",
       "      <td>0.010618</td>\n",
       "      <td>0.011164</td>\n",
       "      <td>0.009977</td>\n",
       "      <td>0.010997</td>\n",
       "      <td>0.012015</td>\n",
       "      <td>0.555663</td>\n",
       "      <td>0.607405</td>\n",
       "      <td>0.093642</td>\n",
       "      <td>0.046856</td>\n",
       "      <td>0.168716</td>\n",
       "      <td>0.189976</td>\n",
       "      <td>0.452707</td>\n",
       "      <td>0.420377</td>\n",
       "      <td>0.388268</td>\n",
       "      <td>0.367025</td>\n",
       "      <td>0.348110</td>\n",
       "      <td>0.318483</td>\n",
       "      <td>0.635849</td>\n",
       "      <td>0.661984</td>\n",
       "      <td>0.681741</td>\n",
       "      <td>0.690672</td>\n",
       "      <td>0.696170</td>\n",
       "      <td>0.700159</td>\n",
       "      <td>0.521552</td>\n",
       "      <td>0.521552</td>\n",
       "      <td>0.441607</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.885999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.534240</td>\n",
       "      <td>0.908265</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.697869</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.611099</td>\n",
       "      <td>0.278265</td>\n",
       "      <td>0.250849</td>\n",
       "      <td>0.240444</td>\n",
       "      <td>0.325395</td>\n",
       "      <td>0.166797</td>\n",
       "      <td>0.198256</td>\n",
       "      <td>0.263813</td>\n",
       "      <td>0.686794</td>\n",
       "      <td>0.124174</td>\n",
       "      <td>0.141736</td>\n",
       "      <td>0.258724</td>\n",
       "      <td>0.590506</td>\n",
       "      <td>0.313245</td>\n",
       "      <td>0.213043</td>\n",
       "      <td>0.426767</td>\n",
       "      <td>0.349347</td>\n",
       "      <td>0.937362</td>\n",
       "      <td>0.773249</td>\n",
       "      <td>0.724993</td>\n",
       "      <td>0.607683</td>\n",
       "      <td>0.804996</td>\n",
       "      <td>0.387889</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.552408</td>\n",
       "      <td>0.600282</td>\n",
       "      <td>0.328461</td>\n",
       "      <td>0.528128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-06</th>\n",
       "      <td>0.014062</td>\n",
       "      <td>0.010108</td>\n",
       "      <td>0.011657</td>\n",
       "      <td>0.011734</td>\n",
       "      <td>0.110767</td>\n",
       "      <td>0.284905</td>\n",
       "      <td>0.299663</td>\n",
       "      <td>0.011662</td>\n",
       "      <td>0.010604</td>\n",
       "      <td>0.010171</td>\n",
       "      <td>0.010429</td>\n",
       "      <td>0.010690</td>\n",
       "      <td>0.011262</td>\n",
       "      <td>0.012370</td>\n",
       "      <td>0.009857</td>\n",
       "      <td>0.010850</td>\n",
       "      <td>0.008947</td>\n",
       "      <td>0.010215</td>\n",
       "      <td>0.011117</td>\n",
       "      <td>0.549440</td>\n",
       "      <td>0.592472</td>\n",
       "      <td>0.099328</td>\n",
       "      <td>0.058881</td>\n",
       "      <td>0.170776</td>\n",
       "      <td>0.191253</td>\n",
       "      <td>0.339000</td>\n",
       "      <td>0.326806</td>\n",
       "      <td>0.311313</td>\n",
       "      <td>0.297837</td>\n",
       "      <td>0.284431</td>\n",
       "      <td>0.261982</td>\n",
       "      <td>0.142875</td>\n",
       "      <td>0.348984</td>\n",
       "      <td>0.371920</td>\n",
       "      <td>0.382169</td>\n",
       "      <td>0.387738</td>\n",
       "      <td>0.389433</td>\n",
       "      <td>0.116378</td>\n",
       "      <td>0.116378</td>\n",
       "      <td>0.098539</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.920124</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.811111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.829701</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.986864</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.692447</td>\n",
       "      <td>0.252115</td>\n",
       "      <td>0.230435</td>\n",
       "      <td>0.222069</td>\n",
       "      <td>0.308659</td>\n",
       "      <td>0.132776</td>\n",
       "      <td>0.168471</td>\n",
       "      <td>0.233222</td>\n",
       "      <td>0.629535</td>\n",
       "      <td>0.098752</td>\n",
       "      <td>0.121678</td>\n",
       "      <td>0.224485</td>\n",
       "      <td>0.525199</td>\n",
       "      <td>0.250878</td>\n",
       "      <td>0.162367</td>\n",
       "      <td>0.382396</td>\n",
       "      <td>0.335077</td>\n",
       "      <td>0.928360</td>\n",
       "      <td>0.769951</td>\n",
       "      <td>0.724993</td>\n",
       "      <td>0.607683</td>\n",
       "      <td>0.781830</td>\n",
       "      <td>0.387889</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.552408</td>\n",
       "      <td>0.600282</td>\n",
       "      <td>0.283201</td>\n",
       "      <td>0.433639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-07</th>\n",
       "      <td>0.009916</td>\n",
       "      <td>0.012130</td>\n",
       "      <td>0.014154</td>\n",
       "      <td>0.014948</td>\n",
       "      <td>0.084317</td>\n",
       "      <td>0.477653</td>\n",
       "      <td>0.495395</td>\n",
       "      <td>0.010798</td>\n",
       "      <td>0.009873</td>\n",
       "      <td>0.009530</td>\n",
       "      <td>0.009812</td>\n",
       "      <td>0.010073</td>\n",
       "      <td>0.010616</td>\n",
       "      <td>0.013101</td>\n",
       "      <td>0.010430</td>\n",
       "      <td>0.010220</td>\n",
       "      <td>0.008528</td>\n",
       "      <td>0.009655</td>\n",
       "      <td>0.010386</td>\n",
       "      <td>0.548323</td>\n",
       "      <td>0.588948</td>\n",
       "      <td>0.097846</td>\n",
       "      <td>0.058266</td>\n",
       "      <td>0.168426</td>\n",
       "      <td>0.190259</td>\n",
       "      <td>0.403960</td>\n",
       "      <td>0.378794</td>\n",
       "      <td>0.354247</td>\n",
       "      <td>0.336764</td>\n",
       "      <td>0.320494</td>\n",
       "      <td>0.294116</td>\n",
       "      <td>0.370152</td>\n",
       "      <td>0.522886</td>\n",
       "      <td>0.544773</td>\n",
       "      <td>0.555741</td>\n",
       "      <td>0.562414</td>\n",
       "      <td>0.566152</td>\n",
       "      <td>0.288793</td>\n",
       "      <td>0.288793</td>\n",
       "      <td>0.273470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.949736</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.986508</td>\n",
       "      <td>0.203927</td>\n",
       "      <td>0.759960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.850231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.995284</td>\n",
       "      <td>0.259522</td>\n",
       "      <td>0.236537</td>\n",
       "      <td>0.227639</td>\n",
       "      <td>0.313323</td>\n",
       "      <td>0.158421</td>\n",
       "      <td>0.191296</td>\n",
       "      <td>0.256369</td>\n",
       "      <td>0.675367</td>\n",
       "      <td>0.110057</td>\n",
       "      <td>0.128403</td>\n",
       "      <td>0.233562</td>\n",
       "      <td>0.532028</td>\n",
       "      <td>0.273391</td>\n",
       "      <td>0.176732</td>\n",
       "      <td>0.398152</td>\n",
       "      <td>0.341392</td>\n",
       "      <td>0.928360</td>\n",
       "      <td>0.769951</td>\n",
       "      <td>0.724993</td>\n",
       "      <td>0.607683</td>\n",
       "      <td>0.781830</td>\n",
       "      <td>0.387889</td>\n",
       "      <td>0.012032</td>\n",
       "      <td>0.559350</td>\n",
       "      <td>0.588056</td>\n",
       "      <td>0.292222</td>\n",
       "      <td>0.627118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-10</th>\n",
       "      <td>0.010079</td>\n",
       "      <td>0.005256</td>\n",
       "      <td>0.006827</td>\n",
       "      <td>0.007072</td>\n",
       "      <td>0.091983</td>\n",
       "      <td>0.277616</td>\n",
       "      <td>0.292153</td>\n",
       "      <td>0.007516</td>\n",
       "      <td>0.007475</td>\n",
       "      <td>0.007695</td>\n",
       "      <td>0.008262</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>0.009369</td>\n",
       "      <td>0.009547</td>\n",
       "      <td>0.009137</td>\n",
       "      <td>0.008849</td>\n",
       "      <td>0.007535</td>\n",
       "      <td>0.008933</td>\n",
       "      <td>0.009214</td>\n",
       "      <td>0.540720</td>\n",
       "      <td>0.573631</td>\n",
       "      <td>0.113263</td>\n",
       "      <td>0.084883</td>\n",
       "      <td>0.177197</td>\n",
       "      <td>0.195173</td>\n",
       "      <td>0.296519</td>\n",
       "      <td>0.289392</td>\n",
       "      <td>0.279570</td>\n",
       "      <td>0.268986</td>\n",
       "      <td>0.257645</td>\n",
       "      <td>0.237842</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.223834</td>\n",
       "      <td>0.244124</td>\n",
       "      <td>0.253524</td>\n",
       "      <td>0.257998</td>\n",
       "      <td>0.256681</td>\n",
       "      <td>0.060714</td>\n",
       "      <td>0.060714</td>\n",
       "      <td>0.060714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.959253</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.873810</td>\n",
       "      <td>0.530211</td>\n",
       "      <td>0.699695</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.939439</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.689276</td>\n",
       "      <td>0.230783</td>\n",
       "      <td>0.213728</td>\n",
       "      <td>0.204221</td>\n",
       "      <td>0.328330</td>\n",
       "      <td>0.139764</td>\n",
       "      <td>0.175017</td>\n",
       "      <td>0.243396</td>\n",
       "      <td>0.684068</td>\n",
       "      <td>0.062024</td>\n",
       "      <td>0.094317</td>\n",
       "      <td>0.199048</td>\n",
       "      <td>0.535484</td>\n",
       "      <td>0.221077</td>\n",
       "      <td>0.131722</td>\n",
       "      <td>0.364122</td>\n",
       "      <td>0.357529</td>\n",
       "      <td>0.888824</td>\n",
       "      <td>0.765858</td>\n",
       "      <td>0.724993</td>\n",
       "      <td>0.607683</td>\n",
       "      <td>0.760819</td>\n",
       "      <td>0.387889</td>\n",
       "      <td>0.008226</td>\n",
       "      <td>0.549371</td>\n",
       "      <td>0.591112</td>\n",
       "      <td>0.272686</td>\n",
       "      <td>0.522922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-11</th>\n",
       "      <td>0.004227</td>\n",
       "      <td>0.006469</td>\n",
       "      <td>0.008160</td>\n",
       "      <td>0.012457</td>\n",
       "      <td>0.078067</td>\n",
       "      <td>0.518221</td>\n",
       "      <td>0.535907</td>\n",
       "      <td>0.007178</td>\n",
       "      <td>0.006861</td>\n",
       "      <td>0.007026</td>\n",
       "      <td>0.007582</td>\n",
       "      <td>0.008005</td>\n",
       "      <td>0.008658</td>\n",
       "      <td>0.006758</td>\n",
       "      <td>0.008501</td>\n",
       "      <td>0.007828</td>\n",
       "      <td>0.007333</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.008446</td>\n",
       "      <td>0.540820</td>\n",
       "      <td>0.574572</td>\n",
       "      <td>0.123311</td>\n",
       "      <td>0.101508</td>\n",
       "      <td>0.182845</td>\n",
       "      <td>0.198550</td>\n",
       "      <td>0.404152</td>\n",
       "      <td>0.375192</td>\n",
       "      <td>0.350288</td>\n",
       "      <td>0.333117</td>\n",
       "      <td>0.317107</td>\n",
       "      <td>0.290916</td>\n",
       "      <td>0.374424</td>\n",
       "      <td>0.391168</td>\n",
       "      <td>0.528832</td>\n",
       "      <td>0.539479</td>\n",
       "      <td>0.546008</td>\n",
       "      <td>0.548558</td>\n",
       "      <td>0.299999</td>\n",
       "      <td>0.299999</td>\n",
       "      <td>0.299999</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.957295</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.150794</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.705161</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.866020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997756</td>\n",
       "      <td>0.248102</td>\n",
       "      <td>0.228206</td>\n",
       "      <td>0.217599</td>\n",
       "      <td>0.335463</td>\n",
       "      <td>0.160582</td>\n",
       "      <td>0.191529</td>\n",
       "      <td>0.258070</td>\n",
       "      <td>0.692865</td>\n",
       "      <td>0.073323</td>\n",
       "      <td>0.100524</td>\n",
       "      <td>0.210413</td>\n",
       "      <td>0.552268</td>\n",
       "      <td>0.272681</td>\n",
       "      <td>0.177489</td>\n",
       "      <td>0.399626</td>\n",
       "      <td>0.371975</td>\n",
       "      <td>0.888824</td>\n",
       "      <td>0.765858</td>\n",
       "      <td>0.724993</td>\n",
       "      <td>0.607683</td>\n",
       "      <td>0.760819</td>\n",
       "      <td>0.387889</td>\n",
       "      <td>0.006016</td>\n",
       "      <td>0.553400</td>\n",
       "      <td>0.599577</td>\n",
       "      <td>0.290308</td>\n",
       "      <td>0.659167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-02</th>\n",
       "      <td>0.893993</td>\n",
       "      <td>0.897090</td>\n",
       "      <td>0.900191</td>\n",
       "      <td>0.881218</td>\n",
       "      <td>0.078973</td>\n",
       "      <td>0.364739</td>\n",
       "      <td>0.381395</td>\n",
       "      <td>0.897645</td>\n",
       "      <td>0.899378</td>\n",
       "      <td>0.903522</td>\n",
       "      <td>0.905376</td>\n",
       "      <td>0.899590</td>\n",
       "      <td>0.895577</td>\n",
       "      <td>0.898930</td>\n",
       "      <td>0.892368</td>\n",
       "      <td>0.886358</td>\n",
       "      <td>0.886905</td>\n",
       "      <td>0.873089</td>\n",
       "      <td>0.858397</td>\n",
       "      <td>0.683652</td>\n",
       "      <td>0.623140</td>\n",
       "      <td>0.680998</td>\n",
       "      <td>0.779055</td>\n",
       "      <td>0.581035</td>\n",
       "      <td>0.392764</td>\n",
       "      <td>0.655725</td>\n",
       "      <td>0.672267</td>\n",
       "      <td>0.683861</td>\n",
       "      <td>0.688523</td>\n",
       "      <td>0.691451</td>\n",
       "      <td>0.684894</td>\n",
       "      <td>0.151919</td>\n",
       "      <td>0.175011</td>\n",
       "      <td>0.279490</td>\n",
       "      <td>0.358153</td>\n",
       "      <td>0.705427</td>\n",
       "      <td>0.799506</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.827740</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.653989</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.723016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.766677</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.262735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.752177</td>\n",
       "      <td>0.135004</td>\n",
       "      <td>0.141873</td>\n",
       "      <td>0.132575</td>\n",
       "      <td>0.997166</td>\n",
       "      <td>0.641394</td>\n",
       "      <td>0.690070</td>\n",
       "      <td>0.646088</td>\n",
       "      <td>0.942287</td>\n",
       "      <td>0.561995</td>\n",
       "      <td>0.474841</td>\n",
       "      <td>0.553193</td>\n",
       "      <td>0.867978</td>\n",
       "      <td>0.547438</td>\n",
       "      <td>0.501281</td>\n",
       "      <td>0.534467</td>\n",
       "      <td>0.845026</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.584393</td>\n",
       "      <td>0.447360</td>\n",
       "      <td>0.660386</td>\n",
       "      <td>0.414508</td>\n",
       "      <td>0.686188</td>\n",
       "      <td>0.729003</td>\n",
       "      <td>0.816130</td>\n",
       "      <td>0.824903</td>\n",
       "      <td>0.585653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-05</th>\n",
       "      <td>0.891491</td>\n",
       "      <td>0.886304</td>\n",
       "      <td>0.901045</td>\n",
       "      <td>0.872148</td>\n",
       "      <td>0.049855</td>\n",
       "      <td>0.368893</td>\n",
       "      <td>0.385622</td>\n",
       "      <td>0.895969</td>\n",
       "      <td>0.900304</td>\n",
       "      <td>0.906169</td>\n",
       "      <td>0.908976</td>\n",
       "      <td>0.903724</td>\n",
       "      <td>0.900121</td>\n",
       "      <td>0.901230</td>\n",
       "      <td>0.894775</td>\n",
       "      <td>0.890377</td>\n",
       "      <td>0.889166</td>\n",
       "      <td>0.880168</td>\n",
       "      <td>0.864888</td>\n",
       "      <td>0.658260</td>\n",
       "      <td>0.579359</td>\n",
       "      <td>0.693181</td>\n",
       "      <td>0.774199</td>\n",
       "      <td>0.601496</td>\n",
       "      <td>0.410985</td>\n",
       "      <td>0.585555</td>\n",
       "      <td>0.618938</td>\n",
       "      <td>0.643091</td>\n",
       "      <td>0.653188</td>\n",
       "      <td>0.659828</td>\n",
       "      <td>0.657850</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040830</td>\n",
       "      <td>0.550699</td>\n",
       "      <td>0.699922</td>\n",
       "      <td>0.558036</td>\n",
       "      <td>0.595918</td>\n",
       "      <td>0.627820</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.767861</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.532540</td>\n",
       "      <td>0.265358</td>\n",
       "      <td>0.615042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.331606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.614796</td>\n",
       "      <td>0.139445</td>\n",
       "      <td>0.146796</td>\n",
       "      <td>0.136998</td>\n",
       "      <td>0.995654</td>\n",
       "      <td>0.657037</td>\n",
       "      <td>0.706756</td>\n",
       "      <td>0.654831</td>\n",
       "      <td>0.957992</td>\n",
       "      <td>0.625749</td>\n",
       "      <td>0.614217</td>\n",
       "      <td>0.597402</td>\n",
       "      <td>0.809098</td>\n",
       "      <td>0.566968</td>\n",
       "      <td>0.545971</td>\n",
       "      <td>0.540733</td>\n",
       "      <td>0.846481</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.584393</td>\n",
       "      <td>0.447360</td>\n",
       "      <td>0.673518</td>\n",
       "      <td>0.666461</td>\n",
       "      <td>0.651197</td>\n",
       "      <td>0.710097</td>\n",
       "      <td>0.845991</td>\n",
       "      <td>0.812397</td>\n",
       "      <td>0.561545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-06</th>\n",
       "      <td>0.871894</td>\n",
       "      <td>0.875934</td>\n",
       "      <td>0.896774</td>\n",
       "      <td>0.878745</td>\n",
       "      <td>0.063997</td>\n",
       "      <td>0.456273</td>\n",
       "      <td>0.473951</td>\n",
       "      <td>0.897118</td>\n",
       "      <td>0.902556</td>\n",
       "      <td>0.909491</td>\n",
       "      <td>0.912996</td>\n",
       "      <td>0.908153</td>\n",
       "      <td>0.904873</td>\n",
       "      <td>0.906937</td>\n",
       "      <td>0.898039</td>\n",
       "      <td>0.893786</td>\n",
       "      <td>0.892925</td>\n",
       "      <td>0.886764</td>\n",
       "      <td>0.871978</td>\n",
       "      <td>0.640163</td>\n",
       "      <td>0.553983</td>\n",
       "      <td>0.699028</td>\n",
       "      <td>0.759795</td>\n",
       "      <td>0.617745</td>\n",
       "      <td>0.427090</td>\n",
       "      <td>0.619884</td>\n",
       "      <td>0.642409</td>\n",
       "      <td>0.660471</td>\n",
       "      <td>0.668347</td>\n",
       "      <td>0.673602</td>\n",
       "      <td>0.669989</td>\n",
       "      <td>0.158289</td>\n",
       "      <td>0.144137</td>\n",
       "      <td>0.140648</td>\n",
       "      <td>0.176961</td>\n",
       "      <td>0.615544</td>\n",
       "      <td>0.744623</td>\n",
       "      <td>0.585000</td>\n",
       "      <td>0.661224</td>\n",
       "      <td>0.661224</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.955304</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.211905</td>\n",
       "      <td>0.660121</td>\n",
       "      <td>0.650237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.414185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999642</td>\n",
       "      <td>0.126775</td>\n",
       "      <td>0.132546</td>\n",
       "      <td>0.124385</td>\n",
       "      <td>0.992359</td>\n",
       "      <td>0.704268</td>\n",
       "      <td>0.775150</td>\n",
       "      <td>0.693181</td>\n",
       "      <td>0.938461</td>\n",
       "      <td>0.678132</td>\n",
       "      <td>0.720736</td>\n",
       "      <td>0.628271</td>\n",
       "      <td>0.803693</td>\n",
       "      <td>0.587559</td>\n",
       "      <td>0.560955</td>\n",
       "      <td>0.549765</td>\n",
       "      <td>0.832078</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.585100</td>\n",
       "      <td>0.528656</td>\n",
       "      <td>0.707623</td>\n",
       "      <td>0.724974</td>\n",
       "      <td>0.653530</td>\n",
       "      <td>0.693485</td>\n",
       "      <td>0.831883</td>\n",
       "      <td>0.809865</td>\n",
       "      <td>0.587424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-07</th>\n",
       "      <td>0.881067</td>\n",
       "      <td>0.882156</td>\n",
       "      <td>0.897628</td>\n",
       "      <td>0.877920</td>\n",
       "      <td>0.063709</td>\n",
       "      <td>0.414733</td>\n",
       "      <td>0.432098</td>\n",
       "      <td>0.897601</td>\n",
       "      <td>0.904117</td>\n",
       "      <td>0.912167</td>\n",
       "      <td>0.916437</td>\n",
       "      <td>0.912073</td>\n",
       "      <td>0.909204</td>\n",
       "      <td>0.902508</td>\n",
       "      <td>0.902106</td>\n",
       "      <td>0.896585</td>\n",
       "      <td>0.896275</td>\n",
       "      <td>0.893865</td>\n",
       "      <td>0.877680</td>\n",
       "      <td>0.620857</td>\n",
       "      <td>0.528746</td>\n",
       "      <td>0.707715</td>\n",
       "      <td>0.752781</td>\n",
       "      <td>0.635288</td>\n",
       "      <td>0.443817</td>\n",
       "      <td>0.612263</td>\n",
       "      <td>0.636928</td>\n",
       "      <td>0.656422</td>\n",
       "      <td>0.664890</td>\n",
       "      <td>0.670541</td>\n",
       "      <td>0.667403</td>\n",
       "      <td>0.123148</td>\n",
       "      <td>0.110479</td>\n",
       "      <td>0.107883</td>\n",
       "      <td>0.145919</td>\n",
       "      <td>0.223962</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.522472</td>\n",
       "      <td>0.630435</td>\n",
       "      <td>0.653061</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.964088</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.626190</td>\n",
       "      <td>0.271400</td>\n",
       "      <td>0.647590</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.478870</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.601904</td>\n",
       "      <td>0.117217</td>\n",
       "      <td>0.121837</td>\n",
       "      <td>0.114880</td>\n",
       "      <td>0.991503</td>\n",
       "      <td>0.729003</td>\n",
       "      <td>0.799412</td>\n",
       "      <td>0.714315</td>\n",
       "      <td>0.926131</td>\n",
       "      <td>0.674483</td>\n",
       "      <td>0.702573</td>\n",
       "      <td>0.626009</td>\n",
       "      <td>0.803358</td>\n",
       "      <td>0.547370</td>\n",
       "      <td>0.484691</td>\n",
       "      <td>0.534087</td>\n",
       "      <td>0.796324</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.585100</td>\n",
       "      <td>0.528656</td>\n",
       "      <td>0.707623</td>\n",
       "      <td>0.724974</td>\n",
       "      <td>0.673419</td>\n",
       "      <td>0.679601</td>\n",
       "      <td>0.803903</td>\n",
       "      <td>0.802354</td>\n",
       "      <td>0.574369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-08</th>\n",
       "      <td>0.880651</td>\n",
       "      <td>0.883401</td>\n",
       "      <td>0.902754</td>\n",
       "      <td>0.879982</td>\n",
       "      <td>0.029285</td>\n",
       "      <td>0.430819</td>\n",
       "      <td>0.448335</td>\n",
       "      <td>0.898631</td>\n",
       "      <td>0.905810</td>\n",
       "      <td>0.914770</td>\n",
       "      <td>0.919737</td>\n",
       "      <td>0.915836</td>\n",
       "      <td>0.913385</td>\n",
       "      <td>0.900208</td>\n",
       "      <td>0.904567</td>\n",
       "      <td>0.900568</td>\n",
       "      <td>0.900443</td>\n",
       "      <td>0.897591</td>\n",
       "      <td>0.883726</td>\n",
       "      <td>0.603767</td>\n",
       "      <td>0.509999</td>\n",
       "      <td>0.716453</td>\n",
       "      <td>0.747702</td>\n",
       "      <td>0.652386</td>\n",
       "      <td>0.460222</td>\n",
       "      <td>0.625526</td>\n",
       "      <td>0.645455</td>\n",
       "      <td>0.662476</td>\n",
       "      <td>0.670071</td>\n",
       "      <td>0.675186</td>\n",
       "      <td>0.671435</td>\n",
       "      <td>0.184306</td>\n",
       "      <td>0.162842</td>\n",
       "      <td>0.156874</td>\n",
       "      <td>0.192447</td>\n",
       "      <td>0.266510</td>\n",
       "      <td>0.675036</td>\n",
       "      <td>0.550562</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.673469</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.982962</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.157603</td>\n",
       "      <td>0.747726</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.504807</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.996153</td>\n",
       "      <td>0.157088</td>\n",
       "      <td>0.167570</td>\n",
       "      <td>0.154297</td>\n",
       "      <td>0.974465</td>\n",
       "      <td>0.722274</td>\n",
       "      <td>0.791487</td>\n",
       "      <td>0.706359</td>\n",
       "      <td>0.935130</td>\n",
       "      <td>0.665524</td>\n",
       "      <td>0.691118</td>\n",
       "      <td>0.618044</td>\n",
       "      <td>0.811537</td>\n",
       "      <td>0.559674</td>\n",
       "      <td>0.491495</td>\n",
       "      <td>0.536487</td>\n",
       "      <td>0.819388</td>\n",
       "      <td>0.052337</td>\n",
       "      <td>0.085628</td>\n",
       "      <td>0.585100</td>\n",
       "      <td>0.528656</td>\n",
       "      <td>0.707623</td>\n",
       "      <td>0.724974</td>\n",
       "      <td>0.696624</td>\n",
       "      <td>0.681398</td>\n",
       "      <td>0.818481</td>\n",
       "      <td>0.802155</td>\n",
       "      <td>0.593527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1030 rows × 233 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Open      High       Low  ...  5Y TY ^FVX    CAC 40  CAC Returns\n",
       "2018-12-05  0.018288  0.017305  0.020732  ...    0.600282  0.328461     0.528128\n",
       "2018-12-06  0.014062  0.010108  0.011657  ...    0.600282  0.283201     0.433639\n",
       "2018-12-07  0.009916  0.012130  0.014154  ...    0.588056  0.292222     0.627118\n",
       "2018-12-10  0.010079  0.005256  0.006827  ...    0.591112  0.272686     0.522922\n",
       "2018-12-11  0.004227  0.006469  0.008160  ...    0.599577  0.290308     0.659167\n",
       "...              ...       ...       ...  ...         ...       ...          ...\n",
       "2022-12-02  0.893993  0.897090  0.900191  ...    0.816130  0.824903     0.585653\n",
       "2022-12-05  0.891491  0.886304  0.901045  ...    0.845991  0.812397     0.561545\n",
       "2022-12-06  0.871894  0.875934  0.896774  ...    0.831883  0.809865     0.587424\n",
       "2022-12-07  0.881067  0.882156  0.897628  ...    0.803903  0.802354     0.574369\n",
       "2022-12-08  0.880651  0.883401  0.902754  ...    0.818481  0.802155     0.593527\n",
       "\n",
       "[1030 rows x 233 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(data)\n",
    "data_scaled = pd.DataFrame(scaler.fit_transform(data), columns = data.columns, index = data.index)\n",
    "data_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1f7363a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo stable baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0973f3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://github.com/stefan-jansen/machine-learning-for-trading/blob/main/24_alpha_factor_library/04_factor_evaluation.ipynb\n",
    "    https://danilzherebtsov.medium.com/automatic-feature-selection-in-python-f72ec69215fe\n",
    "    https://tsfresh.readthedocs.io/en/v0.1.2/text/quick_start.html   \n",
    "    https://github.com/8ball030/FTXIndicators\n",
    "    https://github.com/8ball030/indicator_part_2\n",
    "        =qstats https://github.com/tensortrade-org/tensortrade/blob/master/examples/train_and_evaluate.ipynb\n",
    "         https://tsfresh.readthedocs.io/en/latest/text/data_formats.html#data-formats-label  \n",
    "            https://www.kaggle.com/code/aleksthegreat/lightgbm-feature-importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b14c71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "faire analyse feature importance avec shap sur stacked autoencoders ()\n",
    "faire algo demain\n",
    "\n",
    "par exemple modifier le y_test en return ajuste a la rentabilité predite par Garch ou ewma\n",
    "\n",
    "https://towardsdatascience.com/aifortrading-2edd6fac689d#f982\n",
    "+autoenc\n",
    "\n",
    "#sortino a enormement de succes ici\n",
    "https://towardsdatascience.com/using-reinforcement-learning-to-trade-bitcoin-for-massive-profit-b69d0e8f583b\n",
    "\n",
    "changer la fonction de reward(regarder les liens stockés)\n",
    "ajter kelly + max / cluster    \n",
    "\n",
    "explication drl pmour rapport\n",
    "https://towardsdatascience.com/deep-reinforcement-learning-for-automated-stock-trading-f1dad0126a02 \n",
    "    \n",
    "    \n",
    "autoenc\n",
    "https://towardsdatascience.com/aifortrading-2edd6fac689d#f982\n",
    "from tsfresh import extract_relevant_features\n",
    "\n",
    "https://github.com/mfbalin/Concrete-Autoencoders\n",
    "https://github.com/CAG9/Autoencoder-Feature-Extraction\n",
    "https://github.com/zahraatashgahi/QuickSelection\n",
    "https://github.com/panda1949/AEFS\n",
    "https://github.com/hamaadshah/autoencoders_pytorch\n",
    "https://medium.com/@a.mirzaei69/how-to-use-deep-learning-for-feature-selection-python-keras-24a68bef1e33\n",
    "    \n",
    "feat importance + idee risk management (incorporer EWMA a la place par exemple)\n",
    "voir kernelpca (dans le .docx)\n",
    "\n",
    "https://medium.com/coinmonks/crypto-feature-importance-for-deep-reinforcement-learning-38416616c2a36-8416616c2a36 \n",
    "https://medium.com/@CoderBurnt\n",
    "\n",
    "shap value en fonction du temps https://github.com/dynamik1703/gym_longicontrol/blob/master/Jupyter/LongiControl_SHAP.ipynb    \n",
    "    \n",
    "Support vector machines (SVMs) and decision trees are not strictly linear methods, as they can capture complex relationships between features and the target variable. However, they do not explicitly model non-linear relationships in the data, which means that there is a risk that they may not capture all of the relevant features in a non-linear dataset.\n",
    "In the case of decision trees, the tree structure allows the model to consider multiple features in making predictions, but it does not explicitly model interactions between features. This means that decision trees may not be able to capture non-linear relationships between features that are not evident from the individual features themselves.\n",
    "SVMs, on the other hand, use a hyperplane to separate different classes of data, which allows them to capture complex relationships between features. However, the hyperplane is defined by a linear combination of the input features, so SVMs may not be able to capture non-linear relationships between features that cannot be represented by a linear combination.\n",
    "In general, it is always a good idea to carefully consider the characteristics of your data when selecting a feature selection technique. If your data contains complex non-linear relationships, it may be worth exploring non-linear feature selection techniques, such as artificial neural networks, in order to identify the most relevant features for your financial reinforcement learning model.    \n",
    "    \n",
    "Human: can auto encoder be used to reduce feature space of non linear data?\n",
    "AI: Yes, Auto-Encoders can be used to reduce the feature space of non-linear data. Auto-Encoders are a type of neural network that is used for unsupervised learning. It works by encoding input data into its equivalent lower dimensional representations, thus reducing the feature space. This can be useful for finding patterns in non-linear data and can be used for dimensionality reduction.\n",
    "Human: can I see which features are the most important in autoencoders result ? like shap analysis\n",
    "AI: Yes, you can see which features are most important in an autoencoder's result by using a technique called Shap Analysis. Shap Analysis is a method used to analyze the output of a model by calculating the contribution of each feature to an individual prediction. This can help identify which features had the greatest impact on a model's prediction and can help you better understand the workings of an autoencoder.\n",
    "Human: so this could help me optimize my inputs for my DRL algorithm?\n",
    "AI: Yes, by using Shap Analysis you can identify which features have the most significant impact on your Autoencoder's output. This can be useful for optimizing your inputs for your Deep Reinforcement Learning algorithm. By identifying the important features, you can then adjust or remove unnecessary features to improve the accuracy of your model.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2af155c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#verif l'heure des valeurs obtenues par yfinance pour savoir si enlever derniere ligne ou pas \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "515f665e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#understood later that filter based methods are bad for non linear data\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "Y = data_scaled['Returns'].shift(-1).iloc[:-1].rename(\"return n+1\")\n",
    "X = data_scaled.iloc[:-1,:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073661d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = yourdata.corr()\n",
    "print(corr_matrix[\"your_target_variable\"].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f21fbd03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Returns n-5</th>\n",
       "      <th>alpha22</th>\n",
       "      <th>alpha42</th>\n",
       "      <th>alpha101</th>\n",
       "      <th>CAC 40</th>\n",
       "      <th>alpha78</th>\n",
       "      <th>alpha60</th>\n",
       "      <th>Returns n-7</th>\n",
       "      <th>alpha81</th>\n",
       "      <th>alpha30</th>\n",
       "      <th>alpha44</th>\n",
       "      <th>alpha24</th>\n",
       "      <th>alpha10</th>\n",
       "      <th>alpha16</th>\n",
       "      <th>alpha18</th>\n",
       "      <th>alpha25</th>\n",
       "      <th>volatility_bbw</th>\n",
       "      <th>Returns n-1</th>\n",
       "      <th>alpha50</th>\n",
       "      <th>alpha34</th>\n",
       "      <th>volatility_dcw</th>\n",
       "      <th>alpha9</th>\n",
       "      <th>alpha47</th>\n",
       "      <th>alpha84</th>\n",
       "      <th>volatility_bbl</th>\n",
       "      <th>Beta 252</th>\n",
       "      <th>alpha20</th>\n",
       "      <th>volatility_dcl</th>\n",
       "      <th>macd_24_52</th>\n",
       "      <th>volume_em</th>\n",
       "      <th>volume_cmf</th>\n",
       "      <th>alpha28</th>\n",
       "      <th>Sharpe 252</th>\n",
       "      <th>alpha33</th>\n",
       "      <th>Returns n-3</th>\n",
       "      <th>alpha51</th>\n",
       "      <th>alpha85</th>\n",
       "      <th>alpha1</th>\n",
       "      <th>volume_sma_em</th>\n",
       "      <th>sma26</th>\n",
       "      <th>...</th>\n",
       "      <th>High</th>\n",
       "      <th>sma8</th>\n",
       "      <th>ema8</th>\n",
       "      <th>sma12</th>\n",
       "      <th>volatility_kcc</th>\n",
       "      <th>sma5</th>\n",
       "      <th>ema5</th>\n",
       "      <th>Close</th>\n",
       "      <th>others_cr</th>\n",
       "      <th>volatility_kch</th>\n",
       "      <th>trend_ichimoku_b</th>\n",
       "      <th>trend_ichimoku_conv</th>\n",
       "      <th>Treynor 52</th>\n",
       "      <th>volatility_dch</th>\n",
       "      <th>alpha27</th>\n",
       "      <th>trend_mass_index</th>\n",
       "      <th>trend_kst_diff</th>\n",
       "      <th>volume_obv</th>\n",
       "      <th>alpha13</th>\n",
       "      <th>alpha6</th>\n",
       "      <th>volatility_bbh</th>\n",
       "      <th>Treynor 26</th>\n",
       "      <th>alpha75</th>\n",
       "      <th>alpha7</th>\n",
       "      <th>CAC Returns</th>\n",
       "      <th>momentum_uo</th>\n",
       "      <th>Treynor 252</th>\n",
       "      <th>alpha15</th>\n",
       "      <th>alpha83</th>\n",
       "      <th>alpha3</th>\n",
       "      <th>macd_12_26</th>\n",
       "      <th>alpha55</th>\n",
       "      <th>alpha2</th>\n",
       "      <th>momentum_stoch_rsi_d</th>\n",
       "      <th>stochrsi20</th>\n",
       "      <th>Beta 126</th>\n",
       "      <th>alpha17</th>\n",
       "      <th>alpha52</th>\n",
       "      <th>alpha32</th>\n",
       "      <th>alpha53</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f_reg_score</th>\n",
       "      <td>11.800911</td>\n",
       "      <td>6.274894</td>\n",
       "      <td>4.820948</td>\n",
       "      <td>4.61766</td>\n",
       "      <td>4.110306</td>\n",
       "      <td>3.836341</td>\n",
       "      <td>3.658976</td>\n",
       "      <td>3.364471</td>\n",
       "      <td>3.326426</td>\n",
       "      <td>3.170938</td>\n",
       "      <td>3.066855</td>\n",
       "      <td>2.973161</td>\n",
       "      <td>2.641064</td>\n",
       "      <td>2.502518</td>\n",
       "      <td>2.160708</td>\n",
       "      <td>2.146159</td>\n",
       "      <td>2.082352</td>\n",
       "      <td>1.899992</td>\n",
       "      <td>1.820774</td>\n",
       "      <td>1.814004</td>\n",
       "      <td>1.797391</td>\n",
       "      <td>1.778425</td>\n",
       "      <td>1.736567</td>\n",
       "      <td>1.703595</td>\n",
       "      <td>1.527655</td>\n",
       "      <td>1.491882</td>\n",
       "      <td>1.468174</td>\n",
       "      <td>1.455552</td>\n",
       "      <td>1.435456</td>\n",
       "      <td>1.357575</td>\n",
       "      <td>1.294071</td>\n",
       "      <td>1.26172</td>\n",
       "      <td>1.256689</td>\n",
       "      <td>1.245962</td>\n",
       "      <td>1.214084</td>\n",
       "      <td>1.161836</td>\n",
       "      <td>1.151399</td>\n",
       "      <td>1.122638</td>\n",
       "      <td>1.121071</td>\n",
       "      <td>1.107727</td>\n",
       "      <td>...</td>\n",
       "      <td>0.928533</td>\n",
       "      <td>0.916442</td>\n",
       "      <td>0.916012</td>\n",
       "      <td>0.915301</td>\n",
       "      <td>0.909298</td>\n",
       "      <td>0.894965</td>\n",
       "      <td>0.891874</td>\n",
       "      <td>0.889075</td>\n",
       "      <td>0.889075</td>\n",
       "      <td>0.880438</td>\n",
       "      <td>0.866904</td>\n",
       "      <td>0.846897</td>\n",
       "      <td>0.845643</td>\n",
       "      <td>0.842312</td>\n",
       "      <td>0.830808</td>\n",
       "      <td>0.823706</td>\n",
       "      <td>0.814022</td>\n",
       "      <td>0.810369</td>\n",
       "      <td>0.801904</td>\n",
       "      <td>0.752639</td>\n",
       "      <td>0.740562</td>\n",
       "      <td>0.697297</td>\n",
       "      <td>0.693718</td>\n",
       "      <td>0.685296</td>\n",
       "      <td>0.644416</td>\n",
       "      <td>0.636674</td>\n",
       "      <td>0.634706</td>\n",
       "      <td>0.626959</td>\n",
       "      <td>0.611247</td>\n",
       "      <td>0.601213</td>\n",
       "      <td>0.597632</td>\n",
       "      <td>0.59712</td>\n",
       "      <td>0.587688</td>\n",
       "      <td>0.580258</td>\n",
       "      <td>0.575437</td>\n",
       "      <td>0.568827</td>\n",
       "      <td>0.56714</td>\n",
       "      <td>0.543897</td>\n",
       "      <td>0.514381</td>\n",
       "      <td>0.513987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Returns n-5   alpha22   alpha42  ...   alpha52   alpha32   alpha53\n",
       "f_reg_score    11.800911  6.274894  4.820948  ...  0.543897  0.514381  0.513987\n",
       "\n",
       "[1 rows x 102 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import f_regression, mutual_info_regression\n",
    "test = SelectKBest(score_func=f_regression, k=3)\n",
    "fit = test.fit(X, Y)\n",
    "features_scores = pd.DataFrame(fit.scores_, index=X.columns, columns=['f_reg_score'])\n",
    "features_scores[features_scores.iloc[:,0] > 0.5].sort_values(by=['f_reg_score'], ascending = False).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "309e80b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>volatility_kcw</th>\n",
       "      <th>momentum_ppo_signal</th>\n",
       "      <th>volume_fi</th>\n",
       "      <th>CVar 126</th>\n",
       "      <th>volume_adi</th>\n",
       "      <th>trend_trix</th>\n",
       "      <th>alpha101</th>\n",
       "      <th>volatility_dcw</th>\n",
       "      <th>CVar 52</th>\n",
       "      <th>adx30</th>\n",
       "      <th>Treynor 26</th>\n",
       "      <th>WTI Oil Close</th>\n",
       "      <th>trend_macd_signal</th>\n",
       "      <th>trend_kst_sig</th>\n",
       "      <th>Treynor 52</th>\n",
       "      <th>Sortino 252</th>\n",
       "      <th>Sharpe 252</th>\n",
       "      <th>alpha43</th>\n",
       "      <th>rsi14</th>\n",
       "      <th>alpha11</th>\n",
       "      <th>Var 52</th>\n",
       "      <th>RSI n-7</th>\n",
       "      <th>Var 126</th>\n",
       "      <th>volume_nvi</th>\n",
       "      <th>momentum_ao</th>\n",
       "      <th>volume_cmf</th>\n",
       "      <th>trend_aroon_down</th>\n",
       "      <th>momentum_stoch_rsi_k</th>\n",
       "      <th>CCI7</th>\n",
       "      <th>trend_kst</th>\n",
       "      <th>trend_macd</th>\n",
       "      <th>Sortino 52</th>\n",
       "      <th>Beta 52</th>\n",
       "      <th>alpha28</th>\n",
       "      <th>trend_aroon_ind</th>\n",
       "      <th>alpha74</th>\n",
       "      <th>Sortino 26</th>\n",
       "      <th>alpha22</th>\n",
       "      <th>CAC 40</th>\n",
       "      <th>volatility_bbl</th>\n",
       "      <th>rsi10</th>\n",
       "      <th>trend_visual_ichimoku_b</th>\n",
       "      <th>Beta 126</th>\n",
       "      <th>Volume</th>\n",
       "      <th>RSI n-4</th>\n",
       "      <th>RSI n-3</th>\n",
       "      <th>rsi17</th>\n",
       "      <th>Returns n-5</th>\n",
       "      <th>RSI n-5</th>\n",
       "      <th>RSI n-2</th>\n",
       "      <th>alpha40</th>\n",
       "      <th>momentum_stoch_signal</th>\n",
       "      <th>Var 252</th>\n",
       "      <th>trend_aroon_up</th>\n",
       "      <th>trend_adx_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mut_info_scores</th>\n",
       "      <td>0.100919</td>\n",
       "      <td>0.086871</td>\n",
       "      <td>0.072794</td>\n",
       "      <td>0.070104</td>\n",
       "      <td>0.069253</td>\n",
       "      <td>0.066504</td>\n",
       "      <td>0.065109</td>\n",
       "      <td>0.064551</td>\n",
       "      <td>0.063195</td>\n",
       "      <td>0.060693</td>\n",
       "      <td>0.057233</td>\n",
       "      <td>0.05705</td>\n",
       "      <td>0.054656</td>\n",
       "      <td>0.054621</td>\n",
       "      <td>0.053997</td>\n",
       "      <td>0.051478</td>\n",
       "      <td>0.051115</td>\n",
       "      <td>0.050767</td>\n",
       "      <td>0.050531</td>\n",
       "      <td>0.049716</td>\n",
       "      <td>0.049493</td>\n",
       "      <td>0.049233</td>\n",
       "      <td>0.048874</td>\n",
       "      <td>0.047337</td>\n",
       "      <td>0.045698</td>\n",
       "      <td>0.044884</td>\n",
       "      <td>0.044324</td>\n",
       "      <td>0.044282</td>\n",
       "      <td>0.043838</td>\n",
       "      <td>0.042268</td>\n",
       "      <td>0.041785</td>\n",
       "      <td>0.041196</td>\n",
       "      <td>0.040879</td>\n",
       "      <td>0.03856</td>\n",
       "      <td>0.038117</td>\n",
       "      <td>0.037519</td>\n",
       "      <td>0.037352</td>\n",
       "      <td>0.036614</td>\n",
       "      <td>0.036131</td>\n",
       "      <td>0.036076</td>\n",
       "      <td>0.036049</td>\n",
       "      <td>0.03542</td>\n",
       "      <td>0.034811</td>\n",
       "      <td>0.034407</td>\n",
       "      <td>0.033357</td>\n",
       "      <td>0.032388</td>\n",
       "      <td>0.032153</td>\n",
       "      <td>0.031408</td>\n",
       "      <td>0.031296</td>\n",
       "      <td>0.03094</td>\n",
       "      <td>0.030757</td>\n",
       "      <td>0.030527</td>\n",
       "      <td>0.030295</td>\n",
       "      <td>0.030058</td>\n",
       "      <td>0.030037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 volatility_kcw  ...  trend_adx_pos\n",
       "mut_info_scores        0.100919  ...       0.030037\n",
       "\n",
       "[1 rows x 55 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutinfo = SelectKBest(score_func=mutual_info_regression, k=3)\n",
    "mutinfo = mutinfo.fit(X, Y)\n",
    "mut_info_scores = pd.DataFrame(mutinfo.scores_, index=X.columns, columns=['mut_info_scores'])\n",
    "mut_info_scores[mut_info_scores.iloc[:,0]>0.03].sort_values(by=['mut_info_scores'], ascending = False).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "49fde82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features in the green area: ['momentum_ppo_hist', 'momentum_pvo_signal', 'Returns n-4', 'Returns n-7', 'alpha11', 'alpha24', 'Treynor 52', 'Treynor 26', 'WTI Oil Close', 'CAC 40']\n",
      "features in the blue area: ['volume_em', 'volatility_dcw', 'alpha25']\n"
     ]
    }
   ],
   "source": [
    "from boruta import BorutaPy\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "###initialize Boruta\n",
    "\n",
    "forest = RandomForestRegressor()\n",
    "\n",
    "boruta = BorutaPy(estimator = forest, n_estimators = 'auto', max_iter = 100)\n",
    "boruta.fit(np.array(X), np.array(Y))\n",
    "green_area = X.columns[boruta.support_].to_list()\n",
    "blue_area = X.columns[boruta.support_weak_].to_list()\n",
    "\n",
    "\n",
    "print('features in the green area:', green_area)\n",
    "print('features in the blue area:', blue_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5871423",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://medium.com/@mahupperich/lstm-xgboost-hybrid-stock-forecasting-2ff9e419c020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "af8f4d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-126-e2aaf409d03c>:2: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  upperMatrix = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['High',\n",
       " 'Low',\n",
       " 'Close',\n",
       " 'Log Returns',\n",
       " 'ema5',\n",
       " 'ema8',\n",
       " 'ema12',\n",
       " 'ema16',\n",
       " 'ema20',\n",
       " 'ema26',\n",
       " 'sma5',\n",
       " 'sma8',\n",
       " 'sma12',\n",
       " 'sma16',\n",
       " 'sma20',\n",
       " 'sma26',\n",
       " 'adx10',\n",
       " 'adx20',\n",
       " 'adx30',\n",
       " 'rsi10',\n",
       " 'rsi14',\n",
       " 'rsi17',\n",
       " 'rsi20',\n",
       " 'rsi25',\n",
       " 'stochrsi17',\n",
       " 'stochrsi20',\n",
       " 'stochrsi25',\n",
       " 'willr14',\n",
       " 'willr17',\n",
       " 'willr20',\n",
       " 'willr25',\n",
       " 'CCI7',\n",
       " 'CCI10',\n",
       " 'CCI14',\n",
       " 'CCI20',\n",
       " 'volume_obv',\n",
       " 'volume_vwap',\n",
       " 'volatility_bbh',\n",
       " 'volatility_bbl',\n",
       " 'volatility_bbp',\n",
       " 'volatility_kcc',\n",
       " 'volatility_kch',\n",
       " 'volatility_kcl',\n",
       " 'volatility_kcp',\n",
       " 'volatility_dcl',\n",
       " 'volatility_dch',\n",
       " 'volatility_dcm',\n",
       " 'volatility_dcw',\n",
       " 'volatility_dcp',\n",
       " 'trend_macd_signal',\n",
       " 'trend_vortex_ind_diff',\n",
       " 'trend_trix',\n",
       " 'trend_kst',\n",
       " 'trend_kst_sig',\n",
       " 'trend_ichimoku_conv',\n",
       " 'trend_ichimoku_base',\n",
       " 'trend_ichimoku_a',\n",
       " 'trend_ichimoku_b',\n",
       " 'trend_visual_ichimoku_a',\n",
       " 'trend_visual_ichimoku_b',\n",
       " 'trend_aroon_ind',\n",
       " 'momentum_stoch_rsi_k',\n",
       " 'momentum_stoch_rsi_d',\n",
       " 'momentum_tsi',\n",
       " 'momentum_stoch',\n",
       " 'momentum_stoch_signal',\n",
       " 'momentum_ao',\n",
       " 'momentum_ppo',\n",
       " 'momentum_ppo_signal',\n",
       " 'momentum_ppo_hist',\n",
       " 'momentum_kama',\n",
       " 'others_dr',\n",
       " 'others_dlr',\n",
       " 'others_cr',\n",
       " 'RSI n-1',\n",
       " 'RSI n-2',\n",
       " 'RSI n-3',\n",
       " 'RSI n-4',\n",
       " 'RSI n-5',\n",
       " 'RSI n-6',\n",
       " 'RSI n-7',\n",
       " 'alpha6',\n",
       " 'alpha10',\n",
       " 'alpha28',\n",
       " 'alpha44',\n",
       " 'alpha51',\n",
       " 'Sortino 252',\n",
       " 'Treynor 252',\n",
       " 'Sortino 126',\n",
       " 'Sortino 52',\n",
       " 'Sharpe 26',\n",
       " 'Sortino 26',\n",
       " 'CVar 252',\n",
       " 'CVar 126',\n",
       " 'CVar 52']"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix = data.corr()\n",
    "upperMatrix = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "corrFeatures = [column for column in upperMatrix.columns if any(upperMatrix[column] > 0.9)]\n",
    "corrFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ae282c",
   "metadata": {},
   "outputs": [],
   "source": [
    "finir ca demain, voir quels parametres marchent le mieux par cluster (sharpe, classic, gold, rates)\n",
    "tester ratios avc garrch ewma\n",
    "finir feature extraction jeudi pr tout consolider jeudi et commencer le bot samedi\n",
    "    \n",
    "edmander a louis d'ajouter plein de facteurs \n",
    "mettre en forme les donnees predites par prophet de louis avec window glissante\n",
    "mettre en forme pivot points\n",
    "calculer previous returns\n",
    "https://github.com/stefan-jansen/machine-learning-for-trading/blob/main/24_alpha_factor_library/01_sample_selection.ipynb\n",
    "    \n",
    "stock cluster\n",
    "n+k valeurs\n",
    "https://medium.com/grabngoinfo/time-series-forecasting-of-bitcoin-prices-using-prophet-1069133708bc\n",
    "https://medium.com/@mahupperich/lstm-xgboost-hybrid-stock-forecasting-2ff9e419c020\n",
    "    https://medium.com/@mahupperich/lstm-xgboost-hybrid-stock-forecasting-2ff9e419c020\n",
    "https://medium.com/grabngoinfo/multivariate-time-series-forecasting-with-seasonality-and-holiday-effect-using-prophet-in-python-d5d4150eeb57\n",
    "https://towardsdatascience.com/temporal-fusion-transformer-googles-model-for-interpretable-time-series-forecasting-5aa17beb621\n",
    "\n",
    "analyse de sentiment\n",
    "\n",
    "\n",
    "parler tentative ratée et inutile DWT + fama\n",
    "\n",
    "\n",
    "\n",
    "extraction de features avec tsfresh\n",
    "https://github.com/LastAncientOne/Deep-Learning-Machine-Learning-Stock/blob/master/Features_Extraction.ipynb\n",
    "https://towardsdatascience.com/boost-your-time-series-forecasts-combining-gradient-boosting-models-with-prophet-features-8e738234ffd\n",
    "\n",
    "avec lien envoyé a tim\n",
    "\n",
    "kelly criterion\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "stacked autoenccc\n",
    "faire feature eng\n",
    "https://towardsdatascience.com/aifortrading-2edd6fac689d\n",
    "\n",
    "https://towardsdatascience.com/temporal-fusion-transformer-googles-model-for-interpretable-time-series-forecasting-5aa17beb621\n",
    "    \n",
    "donner strat a louis\n",
    "strats https://github.com/CryptoRobotFr/TrueStrategy\n",
    "    \n",
    "stacked autoencoders\n",
    "\n",
    "feat eng\n",
    "https://github.com/jo-cho/Technical_Analysis_and_Feature_Engineering/blob/main/5.%20Using%20technical%20indicators%20in%20Meta-labeling.ipynb\n",
    "https://github.com/jo-cho/Technical_Analysis_and_Feature_Engineering/blob/main/Feature%20Engineering%20Exercises.ipynb\n",
    "https://github.com/jo-cho/Technical_Analysis_and_Feature_Engineering\n",
    "https://towardsdatascience.com/feature-engineering-feature-selection-8c1d57af18d2\n",
    "https://app.diagrams.net/#G1CmektTRjLYaDa8Sufs3cZs4cNX5EWFrU\n",
    "    \n",
    "et medium feat eng\n",
    "\n",
    "\n",
    "\n",
    "https://github.com/GoldinLocks/Cryptocurrency-Research-/blob/master/predicting-crypto-prices-with-deep-learning.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bed3a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39435192",
   "metadata": {},
   "outputs": [],
   "source": [
    "bibli\n",
    "https://github.com/stefan-jansen/machine-learning-for-trading/blob/main/24_alpha_factor_library/04_factor_evaluation.ipynb\n",
    "https://github.com/LastAncientOne/Deep-Learning-Machine-Learning-Stock/blob/master/Drop_Highly_Correlated_Features.ipynb\n",
    "https://github.com/LastAncientOne/Deep-Learning-Machine-Learning-Stock/blob/master/Features_Selections_Stock.ipynb\n",
    "https://github.com/LastAncientOne/Deep-Learning-Machine-Learning-Stock/blob/master/Features_Selections.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c0ef3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
